{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Session 3\n",
    "\n",
    "In this session, we will learn how to load multiple files into a `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import packages\n",
    "For this session, we will only need `os` and `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Input Folder\n",
    "Get the path of the desired input folder, which will be wherever you saved `\\Py-R\\data\\session3\\exercise1\\`. Remember to deal with the `\\` characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inpath = r\"C:\\Users\\161289\\Py-R\\data\\session3\\exercise1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, we can actually check what is inside our using the `os` function `listdir()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ET101 1.csv', 'ET101 2.csv', 'ET101 3.csv', 'ET101 4.csv', 'ET101 5.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(inpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you look into our data folder, you'll see that that looks right.  \n",
    "Actually, we'll want to use this list of files, so let's save it to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inpathfiles = os.listdir(inpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This list is what we will use to iterate through using a `for` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, let's create some metadata to insert. We'll have a \"PM6\" module and have the site be \"Lehi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "module = \"PM6\"\n",
    "site = \"Lehi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Process Logic\n",
    "\n",
    "The process we are going to go through here is as follows:\n",
    "- Read each file into a `DataFrame`\n",
    "- Combine all of those `DataFrames` together\n",
    "- Add metadata\n",
    "- Make a `.csv` file of the final desired data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, let's make an empty list. This is going to become a list of `DataFrame` structures. Let's call it 'dfs' (short for `DataFrame`s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, we would want to iterate through the list of files that we have in our input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for filename in inpathfiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You'll see an error occur here if you run it -- this is expected as Python expects some logic to go after the loop conditions, so this loop won't properly run until we add some commands afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So now that we're inside the for loop, we are working with the individual files one at a time. We have the list of filenames that are in the list that we got from `os.listdir`, and we want to read each file into a `DataFrame` and add it to our list `dfs`.  \n",
    "Firstly, we need to get the fully filepath rather than just the file name in order to read the right file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for filename in inpathfiles:\n",
    "    filename = inpath + \"\\\\\" + filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, we would would want to read each file into a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for filename in inpathfiles:\n",
    "    filename = inpath + \"\\\\\" + filename\n",
    "    df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And finally, let's add this `DataFrame` to our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for filename in inpathfiles:\n",
    "    filename = inpath + \"\\\\\" + filename\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, let's combine our list into one `DataFrame`. `pandas` has a function called `concat` that will combine `pandas` objects together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, insert the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "result.insert(0,\"Module\",module)\n",
    "result.insert(0,\"Site\",site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And finally, let's configure our outputh path and write the file out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "outpath = inpath + r\"\\output\"\n",
    "\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "outfile = outpath + r\"\\session3output1.csv\"\n",
    "\n",
    "result.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And that's all for Exercise 1! The final script should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports -- os and pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# input folder\n",
    "inpath = r\"C:\\Users\\161289\\Py-R\\data\\session3\\exercise1\"\n",
    "inpathfiles = os.listdir(inpath)\n",
    "\n",
    "# metadata -- PM6 module, Lehi site\n",
    "module = \"PM6\"\n",
    "site = \"Lehi\"\n",
    "\n",
    "# empty list to collect DataFrames\n",
    "dfs = []\n",
    "\n",
    "# iterate through file list, read data, and add to list\n",
    "for filename in inpathfiles:\n",
    "    filename = inpath + \"\\\\\" + filename\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "\n",
    "# combine list of DataFrames into one DataFrame\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "# insert metadata\n",
    "result.insert(0,\"Module\",module)\n",
    "result.insert(0,\"Site\",site)\n",
    "\n",
    "# output folder and file path\n",
    "outpath = inpath + r\"\\output\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "outfile = outpath + r\"\\session3output1.csv\"\n",
    "\n",
    "# write DataFrame to file\n",
    "result.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 2 -- Practice\n",
    "\n",
    "With that, lets try doing this from scratch again, using the data in the `exercise2` folder and creating the output file `session3output2.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports -- os and pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# input folder and list of files\n",
    "inpath = r\"C:\\Users\\161289\\Py-R\\data\\session3\\exercise2\"\n",
    "inpathfiles = os.listdir(inpath)\n",
    "\n",
    "# metadata -- PM6 module and Lehi site\n",
    "module = \"PM6\"\n",
    "site = \"Lehi\"\n",
    "\n",
    "# empty list to collect Dataframes\n",
    "dfs = []\n",
    "\n",
    "# iterate through file list, read data, and add to list\n",
    "for filename in inpathfiles:\n",
    "    filename = inpath + \"\\\\\" + filename\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "# combine list of Dataframes into one DataFrame\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "# insert metadata\n",
    "result.insert(0,\"Module\",module)\n",
    "result.insert(0,\"Site\",site)\n",
    "\n",
    "# output folder and file path\n",
    "outpath = inpath + r\"\\output\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "outfile = outpath + r\"\\session3output2.csv\"\n",
    "\n",
    "# write DataFrame to file\n",
    "result.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 3 -- Filtering\n",
    "Before moving on, let's cover one more useful tool -- being able to filter through what files you are interested collecting.  \n",
    "If you open your data folder for Session 3 Exercise 3, you'll find that we have the same logs as the previous two exercises. What if we need to do different things to these two kinds of files? How could we go about doing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use `if` statements to do so. We're going to copy Exercise 2 and use it as our base for Exercise 3. Let's say that you wanted to just process the TRD logs in this exercise. Where do you think we could place an `if` statement to filter those out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports -- os and pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# input folder and list of files\n",
    "inpath = r\"C:\\Users\\161289\\Py-R\\data\\session3\\exercise3\"\n",
    "inpathfiles = os.listdir(inpath)\n",
    "\n",
    "# metadata -- PM6 module and Lehi site\n",
    "module = \"PM6\"\n",
    "site = \"Lehi\"\n",
    "\n",
    "# empty list to collect Dataframes\n",
    "dfs = []\n",
    "\n",
    "# iterate through file list, read data, and add to list\n",
    "for filename in inpathfiles:\n",
    "    filename = inpath + \"\\\\\" + filename\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "# combine list of Dataframes into one DataFrame\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "# insert metadata\n",
    "result.insert(0,\"Module\",module)\n",
    "result.insert(0,\"Site\",site)\n",
    "\n",
    "#%% output folder and file path\n",
    "outpath = inpath + r\"\\output\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "outfile = outpath + r\"\\session3output3.csv\"\n",
    "\n",
    "# write DataFrame to file\n",
    "result.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We actually process the files in the `for` loop, so this is where I would place the `if` statment. The condition could be set up to look for `TMP01_TRD.CSV` to filter out just the Exercise 2 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for filename in inpathfiles:\n",
    "    if \"TMP01_TRD.CSV\" in filename:\n",
    "    filename = inpath + \"\\\\\" + filename\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But we can't just simply add in that line -- we have to shift over the indentation so that the statements in the loop are only executed when the condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for filename in inpathfiles:\n",
    "    if \"TMP01_TRD.CSV\" in filename:\n",
    "        filename = inpath + \"\\\\\" + filename\n",
    "        df = pd.read_csv(filename)\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While we used this particular string for filtering, it can be flexible based on what the need is. Sometimes you might just need to filter by a smaller set of characters, like maybe some files contain `TMP02_TRD.CSV` and you also want those, you \n",
    "could just filter by `_TRD.CSV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Strings can also be checked against `startswith()` or `endswith()', so these can come in handy as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"ET101.csv\"\n",
    "filename.endswith(\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"ET101.csv\"\n",
    "filename.startswith(\"ET101\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So our final script looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports -- os and pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# input folder and list of files\n",
    "inpath = r\"C:\\Users\\161289\\Py-R\\data\\session3\\exercise3\"\n",
    "inpathfiles = os.listdir(inpath)\n",
    "\n",
    "# metadata -- PM6 module and Lehi site\n",
    "module = \"PM6\"\n",
    "site = \"Lehi\"\n",
    "\n",
    "# empty list to collect Dataframes\n",
    "dfs = []\n",
    "\n",
    "# iterate through file list, read data, and add to list\n",
    "for filename in inpathfiles:\n",
    "    # check file name\n",
    "    if \"TMP01_TRD.CSV\" in filename:\n",
    "        filename = inpath + \"\\\\\" + filename\n",
    "        df = pd.read_csv(filename)\n",
    "        dfs.append(df)\n",
    "    \n",
    "# combine list of Dataframes into one DataFrame\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "# insert metadata\n",
    "result.insert(0,\"Module\",module)\n",
    "result.insert(0,\"Site\",site)\n",
    "\n",
    "#%% output folder and file path\n",
    "outpath = inpath + r\"\\output\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "outfile = outpath + r\"\\session3output3.csv\"\n",
    "\n",
    "# write DataFrame to file\n",
    "result.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thought Exercise\n",
    "What if we wanted to process both of these at the same time to two different files? What adjustments would we have to make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports -- os and pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# input folder and list of files\n",
    "inpath = r\"C:\\Users\\161289\\Py-R\\data\\session3\\exercise3\"\n",
    "inpathfiles = os.listdir(inpath)\n",
    "\n",
    "# metadata -- PM6 module and Lehi site\n",
    "module = \"PM6\"\n",
    "site = \"Lehi\"\n",
    "\n",
    "# empty list to collect Dataframes\n",
    "dfs = []\n",
    "\n",
    "# iterate through file list, read data, and add to list\n",
    "for filename in inpathfiles:\n",
    "    if \"TMP01_TRD.CSV\" in filename:\n",
    "        filename = inpath + \"\\\\\" + filename\n",
    "        df = pd.read_csv(filename)\n",
    "        dfs.append(df)\n",
    "    \n",
    "# combine list of Dataframes into one DataFrame\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "# insert metadata\n",
    "result.insert(0,\"Module\",module)\n",
    "result.insert(0,\"Site\",site)\n",
    "\n",
    "#%% output folder and file path\n",
    "outpath = inpath + r\"\\output\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "outfile = outpath + r\"\\session3output3.csv\"\n",
    "\n",
    "# write DataFrame to file\n",
    "result.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outline and solution is provided for this exercise in the course files, if you want to try it on your own and check your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap-up\n",
    "That's the end of this session! We'll take a break here, and feel free to try to work out that final though exercise for extra credit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
